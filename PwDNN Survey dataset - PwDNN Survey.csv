Title,Authors,PaperURL,Github1,Github2,Github3,Website1,Website2,Video1,Video2,Video3,Venue,Year,FigureID1,FigureID2,FigureID3,WhoAdded
"Diffusion-based Generation, Optimization, and Planning in 3D Scenes","Siyuan Huang, Zan Wang, Puhao Li, Baoxiong Jia, Tengyu Liu, Yixin Zhu, Wei Liang, Song-Chun Zhu",https://arxiv.org/abs/2301.06015,,,,https://scenediffuser.github.io/,,,,,arxiv,2023,1.jpg,2.jpg,,
VIMA: General Robot Manipulation with Multimodal Prompts,"Yunfan Jiang, Agrim Gupta, Zichen Zhang, Guanzhi Wang, Yongqiang Dou, Yanjun Chen, Li Fei-Fei, Anima Anandkumar, Yuke Zhu, Linxi Fan",https://arxiv.org/abs/2210.03094,,,,,,,,,arxiv,2022,1.jpg,3.jpg,,
Deep Hierarchical Planning from Pixels,"Danijar Hafner, Kuang-Huei Lee, Ian Fischer, Pieter Abbeel",https://arxiv.org/abs/2206.04114,https://github.com/danijar/director,,,https://danijar.com/project/director/,,https://www.youtube.com/watch?v=xDUAOyXiRKQ,,,NeurIPS,2022,1.jpg,2.jpg,,
TERP: Reliable Planning in Uneven Outdoor Environments using Deep Reinforcement Learning,"Kasun Weerakoon, Adarsh Jagan Sathyamoorthy, Utsav Patel, and Dinesh Manocha",https://arxiv.org/abs/2109.05120,,,,https://gamma.umd.edu/researchdirections/crowdmultiagent/terp,,,,,ICRA,2021,2.jpg,3.jpg,,
Average-Reward Learning and Planning with Options,"Yi Wan, Abhishek Naik, Richard S. Sutton",https://arxiv.org/abs/2110.13855,,,,,,,,,arxiv,2021,,,,
World Model as a Graph: Learning Latent Landmarks for Planning,"Lunjun Zhang, Ge Yang, Bradly Stadie",https://arxiv.org/abs/2011.12491,,,,https://sites.google.com/view/latent-landmarks/,,,,,ICML,2020,1.jpg,2.jpg,,
Long-Horizon Visual Planning with Goal-Conditioned Hierarchical Predictors,"*Karl Pertsch,*Oleh Rybkin,Frederik Ebert,Chelsea Finn,Dinesh Jayaraman,Sergey Levine",https://arxiv.org/abs/2006.13205,https://github.com/orybkin/video-gcp,,,https://orybkin.github.io/video-gcp/,,https://www.youtube.com/watch?v=bbIQepxyaVw,,,NeurIPS,2020,3.jpg,4.jpg,,
Efficient Planning in a Compact Latent Action Space,"Danijar Hafner, Kuang-Huei Lee, Ian Fischer, Pieter Abbeel",https://arxiv.org/abs/2208.10291,https://github.com/ZhengyaoJiang/latentplan,,,,,,,,arxiv,2022,1.jpg,2.jpg,,
Transformers are Sample Efficient World Models,"Vincent Micheli, Eloi Alonso, François Fleuret",https://arxiv.org/abs/2209.00588,https://github.com/eloialonso/iris,,,https://www.deepmind.com/publications/a-generalist-agent,,,,,arxiv,2022,1,2,,
A Generalist Agent,"Zhengyao Jiang, Tianjun Zhang, Michael Janner, Yueying Li, Tim Rocktäschel, Edward Grefenstette, Yuandong Tian",https://arxiv.org/abs/2205.06175,,,,,,,,,arXiv,2022,2,3,,
Learning Space Partitions for Path Planning,"Kevin Yang, Tianjun Zhang, Chris Cummins, Brandon Cui, Benoit Steiner, Linnan Wang, Joseph E. Gonzalez, Dan Klein, Yuandong Tian",https://arxiv.org/abs/2106.10544,https://github.com/yangkevin2/neurips2021-lap3,,,,,,,,NeurIPS,2022,1.jpg,3.jpg,,
Toward Discovering Options that Achieve Faster Planning,"Yi Wan, Richard S. Sutton",https://arxiv.org/abs/2205.12515,,,,,,,,,arxiv,2022,2,4,,
Value Function Spaces: Skill-Centric State Abstractions for Long-Horizon Reasoning,"Dhruv Shah, Peng Xu, Yao Lu, Ted Xiao, Alexander Toshev, Sergey Levine, Brian Ichter",https://arxiv.org/abs/2111.03189,,,,,,,,,ICLR,2022,4,6,,
Planning with Diffusion for Flexible Behavior Synthesis,"Michael Janner, Yilun Du, Joshua B. Tenenbaum, Sergey Levine",https://arxiv.org/abs/2205.09991,,,,,,,,,ICML,2022,2,3,,
Hierarchical Representations and Explicit Memory: Learning Effective Navigation Policies on 3D Scene Graphs using Graph Neural Networks,"Zachary Ravichandran, Lisa Peng, Nathan Hughes, J. Daniel Griffith, and Luca Carlone",https://arxiv.org/abs/2108.01176,https://github.com/MIT-TESSE/dsg-rl,,,,,https://www.youtube.com/watch?v=x4LM-g3-uaY,,,ICRA,2022,1,3,,
Decision Transformer: Reinforcement Learning via Sequence Modeling,"ili Chen, Kevin Lu*, Aravind Rajeswaran, Kimin Lee, Aditya Grover, Michael Laskin, Pieter Abbeel, Aravind Srinivas*, Igor Mordatch*",https://arxiv.org/abs/2106.01345,https://github.com/kzl/decision-transformer,,,,,,,,ICML,2021,1,2,,
Discovering and Achieving Goals via World Models,"Russell Mendonca, Oleh Rybkin, Kostas Daniilidis, Danijar Hafner, Deepak Pathak",https://arxiv.org/abs/2110.09514,,,,https://orybkin.github.io/lexa/,,,,,ICML,2021,1,3,,
Diversity-based Trajectory and Goal Selection with Hindsight Experience Replay,"Tianhong Dai, Hengyan Liu, Kai Arulkumaran, Guangyu Ren, Anil Anthony Bharath",https://arxiv.org/abs/2108.07887,,,,,,,,,arxiv,2021,1,2,,
Shortest-Path Constrained Reinforcement Learning for Sparse Reward Tasks,"Sungryull Sohn, Sungtae Lee, Jongwook Choi, Harm van Seijen, Mehdi Fatemi, Honglak Lee",https://arxiv.org/abs/2107.06405,,,,,,https://crossminds.ai/video/shortest-path-constrained-reinforcement-learning-for-sparse-reward-tasks-614bd4193c7a224a90903227/,,,ICML,2021,1,7,,
Model-Based Reinforcement Learning via Latent-Space Collocation,"Oleh Rybkin, Chuning Zhu, Anusha Nagabandi, Kostas Daniilidis, Igor Mordatch, Sergey Levine",https://arxiv.org/abs/2106.13229,,,,https://orybkin.github.io/latco/,,,,,ICML,2021,2,5,,
Skill Preferences: Learning to Extract and Execute Robotic Skills from Human Feedback,"Xiaofei Wang, Kimin Lee, Kourosh Hakhamaneshi, Pieter Abbeel, Michael Laskin",https://arxiv.org/abs/2108.05382,,,,https://sites.google.com/view/skill-pref,,,,,NeurIPS,2021,1,3,,
Learning Transferable Visual Models From Natural Language Supervision,"Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, Ilya Sutskever",https://arxiv.org/abs/2103.00020,https://github.com/openai/CLIP,,,,,,,,PMLR,2021,1,2,,
Skill Discovery for Exploration and Planning using Deep Skill Graphs,"Akhil Bagaria, Jason K Senthil, George Konidaris",https://proceedings.mlr.press/v139/bagaria21a.html,,,,,,,,,ICML,2021,1,2,,
Learning Geometric Reasoning and Control for Long-Horizon Tasks from Visual Input,"Danny Driess, Jung-Su Ha, Russ Tedrake, M. Toussaint",https://www.semanticscholar.org/paper/Learning-Geometric-Reasoning-and-Control-for-Tasks-Driess-Ha/b0829f5c4ae98bcc00e54e1b50400f0523215204,,,,,,https://www.youtube.com/watch?v=AcPWRTkr3_g,,,semanticscholar,2021,1,2,,
Learning to solve sequential physical reasoning problems from a scene image,"Danny Driess, Jung-Su Ha, and Marc Toussaint",https://journals.sagepub.com/doi/full/10.1177/02783649211056967,,,,,,,,,sagepub,2021,1,2,,
Goal-Conditioned Reinforcement Learning with Imagined Subgoals,"Elliot Chane-Sane, Cordelia Schmid, Ivan Laptev",https://arxiv.org/abs/2107.00541,,,,https://www.di.ens.fr/willow/research/ris/,,https://crossminds.ai/video/goal-conditioned-reinforcement-learning-with-imagined-subgoals-614bcccc3c7a224a90902b87/,,,ICML,2021,1,2,,
Sparse Graphical Memory for Robust Planning,"Scott Emmons, Ajay Jain, Michael Laskin, Thanard Kurutach, Pieter Abbeel, Deepak Pathak",https://arxiv.org/abs/2003.06417,,,,https://mishalaskin.github.io/sgm/,,,,,NeurIPS,2020,1,3,,
Hallucinative Topological Memory for Zero-Shot Visual Planning,"Kara Liu, Thanard Kurutach, Christine Tung, Pieter Abbeel, Aviv Tamar",https://arxiv.org/abs/2002.12336,https://github.com/thanard/hallucinative-topological-memory,,,,,https://www.youtube.com/watch?v=SQS7XjcrXtI,,,ICML,2020,2,3,,
Planning to Explore via Self-Supervised World Models,"Ramanan Sekar, Oleh Rybkin, Kostas Daniilidis, Pieter Abbeel, Danijar Hafner, Deepak Pathak",https://arxiv.org/abs/2005.05960,https://github.com/ramanans1/plan2explore,,,,,,,,ICML,2020,1,2,,
Generalized Hindsight for Reinforcement Learning,"Alexander C. Li, Lerrel Pinto, Pieter Abbeel",https://arxiv.org/abs/2002.11708,,,,https://sites.google.com/view/generalized-hindsight,,,,,NeurIPS,2020,1,2,,
Parrot: Data-Driven Behavioral Priors for Reinforcement Learning,"Avi Singh, Huihan Liu, Gaoyue Zhou, Albert Yu, Nicholas Rhinehart, Sergey Levine",https://arxiv.org/abs/2011.10024,,,,https://sites.google.com/view/parrot-rl,,,,,ICLR,2020,1,2,,
ReLMoGen: Leveraging Motion Generation in Reinforcement Learning for Mobile Manipulation,"Fei Xia, Chengshu Li, Roberto Martín-Martín, Or Litany, Alexander Toshev, Silvio Savarese",https://arxiv.org/abs/2008.07792,,,,https://svl.stanford.edu/projects/relmogen/,,,,,ICRA,2020,1,2,,
Deep Skill Chaining,"Akhil Bagaria, George Konidaris",,,,,https://sites.google.com/g.hmc.edu/dsc,,,,,arxiv,2020,2,3,,
Learning Robot Skills with Temporal Variational Inference,"Tanmay Shankar, Abhinav Gupta",https://arxiv.org/abs/2006.16232,,,,,,,,,ICML,2020,1,2,,
Hierarchical Planning for Long-Horizon Manipulation with Geometric and Symbolic Scene Graphs,"Yifeng Zhu, Jonathan Tremblay, Stan Birchfield, Yuke Zhu",https://arxiv.org/abs/2012.07277,,,,,,,,,ICRA,2020,1,2,,
Deep Visual Reasoning: Learning to Predict Action Sequences for Task and Motion Planning from an Initial Scene Image,"Danny Driess, Jung-Su Ha, Marc Toussaint",https://arxiv.org/abs/2006.05398,,,,,,,,,RSS,2020,1,2,,
Dynamics-Aware Unsupervised Discovery of Skills,"Archit Sharma, Shixiang Gu, Sergey Levine, Vikash Kumar, Karol Hausman",https://arxiv.org/abs/1907.01657,https://github.com/google-research/dads,,,,,https://www.youtube.com/watch?v=3RpYykEz1q8,,,ICLR,2019,1,2,,
Planning with Goal-Conditioned Policies,"Soroush Nasiriany, Vitchyr Pong, Steven Lin, Sergey Levine",https://arxiv.org/abs/1911.08453,https://github.com/snasiriany/leap,,,https://sites.google.com/view/goal-planning,,,,,NeurIPS,2019,1,2,,
Search on the Replay Buffer: Bridging Planning and Reinforcement Learning,"Benjamin Eysenbach, Ruslan Salakhutdinov, Sergey Levine",https://arxiv.org/abs/1906.05253,https://github.com/google-research/google-research/tree/master/sorb,,,,,,,,NeurIPS,2019,1,2,,
Floyd-Warshall Reinforcement Learning: Learning from Past Experiences to Reach New Goals,"Vikas Dhiman, Shurjo Banerjee, Jeffrey M. Siskind, Jason J. Corso",https://arxiv.org/abs/1809.09318,,,,,,,,,arxiv,2019,1,7,,
InfoBot: Transfer and Exploration via the Information Bottleneck,"Anirudh Goyal, Riashat Islam, Daniel Strouse, Zafarali Ahmed, Matthew Botvinick, Hugo Larochelle, Yoshua Bengio, Sergey Levine",https://arxiv.org/abs/1901.10902,,,,,,,,,ICLR,2019,1,6,,
Addressing Sample Complexity in Visual Tasks Using HER and Hallucinatory GANs,"Himanshu Sahni, Toby Buckley, Pieter Abbeel, Ilya Kuzovkin",https://arxiv.org/abs/1901.11529,,,,,,,,,arxiv,2019,1,2,,
Discovering Options for Exploration by Minimizing Cover Time,"Yuu Jinnai, Jee Won Park, David Abel, George Konidaris",https://arxiv.org/abs/1903.00606,,,,,,,,,arxiv,2019,2,4,,
Successor Options: An Option Discovery Framework for Reinforcement Learning,"Rahul Ramesh, Manan Tomar, Balaraman Ravindran",https://arxiv.org/abs/1905.05731,,,,,,,,,IJCAI,2019,1,4,,
"Neural Path Planning: Fixed Time, Near-Optimal Path Generation via Oracle Imitation","Mayur J. Bency, Ahmed H. Qureshi, Michael C. Yip",https://arxiv.org/abs/1904.11102,,,,,,,,,arxiv,2019,2,3,,
Semi-Parametric Topological Memory for Navigation,"Nikolay Savinov, Alexey Dosovitskiy, Vladlen Koltun",https://arxiv.org/abs/1803.00653,https://github.com/nsavinov/SPTM,,,,,https://www.youtube.com/watch?v=PyQe7nsedkY,,,ICLR,2018,1,2,,
Automatic Goal Generation for Reinforcement Learning Agents,"Carlos Florensa, David Held, Xinyang Geng, Pieter Abbeel",https://arxiv.org/abs/1705.06366,,,,,,https://vimeo.com/312269573,,,ICML,2018,1,10,,
Finding Options that Minimize Planning Time,"Yuu Jinnai, David Abel, D Ellis Hershkowitz, Michael Littman, George Konidaris",https://arxiv.org/abs/1810.07311,,,,,,,,,arxiv,2018,1,2,,
 Motion Planning Networks,"Ahmed H. Qureshi, Anthony Simeonov, Mayur J. Bency, Michael C. Yip",https://arxiv.org/abs/1806.05767,,,,https://sites.google.com/view/mpnet/home,,,,,arxiv,2018,2,3,,
Differentiable Physics and Stable Modes for Tool-Use and Manipulation Planning,"Marc Toussaint, Kelsey R. Allen, Kevin A. Smith, J. Tenenbaum",https://www.semanticscholar.org/paper/Differentiable-Physics-and-Stable-Modes-for-and-Toussaint-Allen/0e03fc69fdfb33742dd4ae0977298b3cabdf579b,,,,,,https://www.youtube.com/watch?v=ILufu3Iq2SI,,,IJCAI,2018,1,2,,
"Motion Planning Among Dynamic, Decision-Making Agents with Deep Reinforcement Learning","Michael Everett, Yu Fan Chen, Jonathan P. How",https://arxiv.org/abs/1805.01956,https://github.com/mit-acl/cadrl_ros,,,,,,,,IROS,2018,2,3,,
Robot Motion Planning in Learned Latent Spaces,"Brian Ichter, Marco Pavone",https://arxiv.org/abs/1807.10366,https://github.com/StanfordASL/LSBMP,,,,,,,,IROS,2018,1,2,,
Cognitive Mapping and Planning for Visual Navigation,"Saurabh Gupta, Varun Tolani, James Davidson, Sergey Levine, Rahul Sukthankar, Jitendra Malik",https://arxiv.org/abs/1702.03920,,,,https://sites.google.com/view/cognitive-mapping-and-planning/,,,,,CVPR,2017,1,2,,
Learning Sampling Distributions for Robot Motion Planning,"Brian Ichter, James Harrison, Marco Pavone",https://arxiv.org/abs/1709.05448,https://github.com/StanfordASL/LearnedSamplingDistributions,,,,,,,,CVPR,2017,1,2,,
Learning Universal Policies via Text-Guided Video Generation,"Yilun Du * 1 2 Mengjiao Yang * 3 2 Bo Dai 2 Hanjun Dai 2 Ofir Nachum, Joshua B. Tenenbaum 1 Dale Schuurmans 2 4 Pieter Abbeel",https://arxiv.org/abs/2302.00111,https://universal-policy.github.io/unipi/,,,,,,,,arxiv,2023,1,2,,
AdaptDiffuser: Diffusion Models as Adaptive Self-evolving Planners,Zhixuan Liang 1 Yao Mu 1 Mingyu Ding 1 2 Fei Ni 3 Masayoshi Tomizuka 2 Ping Luo,https://arxiv.org/abs/2302.01877,,,,,,,,,arxiv,2023,1,2,,
DALL-E-Bot: Introducing Web-Scale Diffusion Models to Robotics,"Ivan Kapelyukh∗1,2, Vitalis Vosylius∗1, Edward Johns",https://arxiv.org/abs/2210.02438,,,,https://www.robot-learning.uk/dall-e-bot,,,,,arxiv,2022,1,2,,
Conditioned Score-Based Models for Learning Collision-Free Trajectory Generation,"João Carvalho, Mark Baeirl, Julen Urain, Jan Peters",https://openreview.net/forum?id=4Vqu4N1jjrx,,,,,,,,,NeurIPS(Workshop),2022,2,3,,
StructDiffusion: Object-Centric Diffusion for Semantic Rearrangement of Novel Objects,"Weiyu Liu1, Tucker Hermans2, Sonia Chernova1, Chris Paxton3",https://arxiv.org/abs2211.04604,,,,,,,,,arxiv,2022,2,3,,
TransPath: Learning Heuristics For Grid-Based Pathfinding via Transformers,"Daniil Kirilenko, 1 Anton Andreychuk, 2 Aleksandr Panov, 1, 2 Konstantin Yakovlev",https://arxiv.org/abs/2212.11730,,,,,,,,,arxiv,2022,2,3,,
LAD: Language Augmented Diffusion for Reinforcement Learning,"Edwin Zhang1, Yujie Lu1, William Wang1, and Amy Zhang",https://arxiv.org/abs/2210.15629,,,,,,,,,arxiv,2022,1,2,,
Is Conditional Generative Modeling all you need for Decision-Making,"Anurag Ajay, Yilun Du, Abhi Gupta, Joshua Tenenbaum, Tommi Jaakkola, Pulkit Agrawal","https://arxiv.org/abs/2211.15657#:~:text=Conditioning%20on%20a%20single%20constraint,powerful%20tool%20for%20decision%2Dmaking.",,,,https://anuragajay.github.io/decision-diffuser/,,,,,NeurlPS,2022,1,2,,
Learning Neuro-Symbolic Skills for Bilevel Planning,"Tom Silver, Ashay Athalye, Joshua B. Tenenbaum, Tomás Lozano-Pérez, Leslie Pack Kaelbling",https://arxiv.org/abs/2206.10680,,,,,,,,,CoRL,2022,2,3,,
Learning Temporally Extended Skills in Continuous Domains as Symbolic Actions for Planning,"Jan Achterhold, Markus Krimmel, Joerg Stueckler",https://openreview.net/forum?id=t-IO7wCaNgH,,,,,,,,,CoRL,2022,1,2,,
"Do As I Can, Not As I Say: Grounding Language in Robotic Affordances","Michael Ahn, Anthony Brohan, Noah Brown, Yevgen Chebotar, Omar Cortes, Byron David, Chelsea Finn, Chuyuan Fu, Keerthana Gopalakrishnan, Karol Hausman, Alex Herzog, Daniel Ho, Jasmine Hsu, Julian Ibarz, Brian Ichter, Alex Irpan, Eric Jang, Rosario Jauregui Ruano, Kyle Jeffrey, Sally Jesmonth, Nikhil J Joshi, Ryan Julian, Dmitry Kalashnikov, Yuheng Kuang, Kuang-Huei Lee, Sergey Levine, Yao Lu, Linda Luu, Carolina Parada, Peter Pastor, Jornell Quiambao, Kanishka Rao, Jarek Rettinghouse, Diego Reyes, Pierre Sermanet, Nicolas Sievers, Clayton Tan, Alexander Toshev, Vincent Vanhoucke, Fei Xia, Ted Xiao, Peng Xu, Sichun Xu, Mengyuan Yan, Andy Zeng",https://arxiv.org/abs/2204.01691,https://github.com/google-research/google-research/tree/master/saycan,,,https://say-can.github.io/,,https://www.youtube.com/watch?v=ysFav0b472w,https://www.youtube.com/watch?v=Ru23eWAQ6_E,,arxiv,2022,1,2,,
Residual Skill Policies: Learning an Adaptable Skill-based Action Space for Reinforcement Learning for Robotics,"Krishan Rana, Ming Xu, Brendan Tidd, Michael Milford, Niko Suenderhauf",https://arxiv.org/abs/2211.02231,https://github.com/krishanrana/reskill,,,https://krishanrana.github.io/reskill,,,,,CoRL,2022,1,2,,
Accelerating Reinforcement Learning with Learned Skill Priors,Karl Pertsch Youngwoon Lee Joseph J. Lim,https://www.semanticscholar.org/paper/Accelerating-Reinforcement-Learning-with-Learned-Pertsch-Lee/b68b8b980db62308864b2a7d33718182c5f8335b,,,,,,,,,SemanticScholar,2020,1,2,,
